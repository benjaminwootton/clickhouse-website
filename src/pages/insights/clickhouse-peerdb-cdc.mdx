---
title: Integrating Postgres And ClickHouse Using PeerDB
date_published: 2024-12-09
date_updated: 2024-12-09
order: 12
image: /x.jpg
featured_image: 119.jpg
background_color:
    - "#DF6B9C"
    - "#E74C68"
tag: General
description: Why PeerDB is the best solution for integrating data between Postgres and ClickHouse.
featured_posts: 25,29,30,11
authorName1: Benjamin Wootton
authorTitle1: Founder & CTO, Jetstream
authorImage1: /assets/authors/benjamin-wootton.jpg
authorLinkedIn1: https://www.linkedin.com/in/benjaminwootton/
---

import InformationEmbed from 'components/InformationEmbed.astro'
import Article from 'layouts/Article.astro';
import { Picture } from 'astro:assets';
import clickpipespostgrescdc  from 'assets/insights/clickpipespostgrescdc.png';
import peerdbgui from 'assets/insights/peerdbgui.png'
import clickpipespostgres  from 'assets/insights/clickpipespostgres.png';

<Article data={frontmatter}>

In this article we are going to demonstrate how we can use [PeerDB](https://peerdb.io) to integrate data from Postgres to ClickHouse.  

We will discuss both a self hosted open source stack and two fully managed solutions using [PeerDB Cloud](https://peerdb.io/) and [ClickHouse Cloud](https://clickhouse.com).   

## Why Postgres and ClickHouse?

Many data teams use ClickHouse to complement Postgres.  Typically, they begin with Postgres as their transactional application database. Over time, however, they find that the analytical components of their user experience slow down. To address this issue, they add a separate OLAP database better suited for analytics and ClickHouse is often the database of choice.

Once teams decide on Postgres and ClickHouse, the next challenge is to integrate data between the two on an ongoing basis. While several tools can accomplish this, including [Debezium](https://debezium.io/), [AirByte](https://airbyte.io/), and [Fivetran](https://fivetran.com/), it’s worth considering the lesser-known PeerDB, which is particularly well suited for this stack.  There are two key reasons for this.

First, unlike many ETL tools that aim to support a broad range of connectors, PeerDB focuses exclusively on Postgres as a data source.  This specialization has allowed it to develop one of the [fastest and most scalable CDC solutions for Postgres](https://docs.peerdb.io/why-peerdb), with support for advanced Postgres features like complex data types and partitioned tables.

Second, in July 2024, [ClickHouse acquired PeerDB](https://clickhouse.com/blog/clickhouse-acquires-peerdb-to-boost-real-time-analytics-with-postgres-cdc-integration). Since then, the integration between the two platforms has deepened, including the [private preview of PeerDB integrated into ClickHouse Cloud](https://clickhouse.com/blog/postgres-cdc-connector-clickpipes-private-preview). This strategic alignment makes PeerDB the strategic choice when working with Postgres and ClickHouse.

## How PeerDB Works 

PeerDB is responsible for taking data from a Postgres source database and reliably copying it into a target data warehouse, in our case ClickHouse.  

It will integrate all inserts, updates and deletes that occur against selected source tables and apply them to the target continuously and in near real-time.   This means the target tables in ClickHouse should accurately mirror the Postgres source table at any given time.

[Transformations can be applied within PeerDB](https://blog.peerdb.io/row-level-transformations-in-postgres-cdc-using-lua) as data moves between the two systems, helping to keep load off the databases and support use cases such as removing sensitive data or unnesting JSON during the ETL process.  

Architecturally, PeerDB is a set of standalone services which are usually ran through Docker Compose.  It can run on a seperate server or alongside your PeerDB or ClickHouse servers.

PeerDB exposes a UI and a SQL interface to control and monitor it's configuration and behaviour.  

<Picture src={peerdbgui} alt="" />

## CDC vs SQL Integration

There are two options for integrating Postgres and ClickHouse which are referred to as CDC and Streaming Queries.  

CDC (Change Data Capture) is where PeerDB will source data by listening to a log of low level change events emitted from Postgres.  

The Streaming Query route extracts data from the source by issuing a SQL query.  This allows you to do things like select a subset of rows from the table, carry out joins across multiple source tables and apply other transformations at source.  

The SQL Query route is much more flexible, but typically adds more load onto the source database than the CDC approach.   With a fast analytical database like ClickHouse and the option of applying transformations within PeerDB, it may be better to stick to CDC and do any transformation work within ClickHouse away from your production transactional database.

### Open Source vs PeerDB Cloud vs ClickHouse Cloud

As of December 2024, you have three options for making use of PeerDB.

The first is to use the open source PeerDB distribution and run it in a self hosted configuration on your own server.  It is distributed as a set of Docker containers and ran using a Docker compose file which makes it relatively easy to deploy and run. 

Secondly, you can use [PeerDB Cloud], which is a hosted version of PeerDB.  Though this has traditionally supported other databases such as Snowflake and BigQuery, as of the acquisition in July 2024 it only supports ClickHouse Cloud as a destination.  

Finally, you can use a fully managed version which is integrated and embedded into the ClickHouse Cloud UI.  In this instance, it's branded as ClickPipes, though PeerDB is likely used behind the scenes.  

Though PeerDB isn't too tricky to setup and operate, having it deployed and ran for you is one less thing to worry about.  We therefore tend towards one of the hosted options.  

## Setting Up The Integration With PeerDB Open Source

We will begin with a runthrough as to how to self manage PeerDB open source and introduce some of the core concepts.

We won't repeat all of the [PeerDB documentation here](https://docs.peerdb.io/quickstart/quickstart) as the QuickStart guide is clear.  However, these are the steps at a high level:

- Run the PeerDB QuickStart process outlined at the link to clone the Docker compose file and startup scripts onto your server;

- Make any tweaks to the docker compose file needed, including setting the MiniIO hostname (see gotchas below) and other relevant configuration;

- Run the run-peerdb.sh script to start the PeerDB services;

- Access the PeerDB UI in order to configure the source (Postgres) and target (ClickHouse) peer connection details;

- Through the same UI, configure a mirror to integrate the two peers and define the tables that you would like to sync.

At this point, if everything is configured correctly, PeerDB should be ready to move data from Postgres to ClickHouse for your selected tables.  You can monitor the health of the peers and the mirrors through the UI.

## Source Table In Postgres

The QuickStart guide creates a Postgres database called __source__ which contains a table called __test__.  

We can use that table to experiment with PeerDB by inserting data into it which should be mirrored into ClickHouse.  The table has the following schema at the outset:

```
source=# \d+ test
                                              Table "public.test"
 Column |  Type   | Collation | Nullable |           Default            | Storage  | Stats target | Description
--------+---------+-----------+----------+------------------------------+----------+--------------+-------------
 id     | integer |           | not null | generated always as identity | plain    |              |
 c1     | integer |           |          |                              | plain    |              |
 c2     | integer |           |          |                              | plain    |              |
 t      | text    |           |          |                              | extended |              |
Indexes:
    "test_pkey" PRIMARY KEY, btree (id)
Publications:
    "peerflow_pub_main"
Access method: heap
```

## Generating Test Data

To create synthetic test data in Postgres you can use the following technique.  Begin by creating 10 rows in the test table:

```
insert into test ( c1, c2 ) 
select random()::float * 1000, random()::float * 10000 from generate_series( 1, 10 );
```

Over time you can generate more test data to benchmark the performance of your setup.

### How Data Is Represented In ClickHouse 

Within a minute, the table will be created in ClickHouse and the data should be replicated into it with the schema matching the Postgres schema.  Columns for the sync time, the deleted flag and the peerdb version are added automatically by PeerDB:

```
SELECT *
FROM public_test
LIMIT 5

Query id: f07af228-f7bb-4764-929a-12da5d2ae26e

   ┌─id─┬──c1─┬───c2─┬─t─┬─────────────_peerdb_synced_at─┬─_peerdb_is_deleted─┬─_peerdb_version─┐
1. │  1 │ 581 │ 7417 │   │ 2024-12-09 14:18:20.056000000 │                  0 │               0 │
2. │  2 │ 242 │ 8599 │   │ 2024-12-09 14:18:20.056000000 │                  0 │               0 │
3. │  3 │ 793 │   67 │   │ 2024-12-09 14:18:20.056000000 │                  0 │               0 │
4. │  4 │ 444 │ 2072 │   │ 2024-12-09 14:18:20.056000000 │                  0 │               0 │
5. │  5 │ 956 │  609 │   │ 2024-12-09 14:18:20.056000000 │                  0 │               0 │
   └────┴─────┴──────┴───┴───────────────────────────────┴────────────────────┴─────────────────┘

```

By default, PeerDB will create a ReplacingMergeTree table in ClickHouse.  This is suitable for most use cases, but you can also create a regular MergeTree table if you need to.  As with anything in ClickHouse, it's important to be aware of the semantics of the table engine that you choose.

### Updates and Deletes

If you update a row in Postgres, a new row is created in your ClickHouse target table.  If you stick with the ReplacingMergeTree, the new row will effectively replace the old row at the next merge, giving you correct update semantics in your target table.  

```
SELECT *
FROM public_test
WHERE c3 > 100
LIMIT 5

Query id: 190cd6d5-92ea-4ca2-8bfc-9d52f349299c

   ┌─id─┬──c1─┬─c2─┬─t─┬─────────────_peerdb_synced_at─┬─_peerdb_is_deleted─┬─────_peerdb_version─┬───c3─┐
1. │ 13 │ 887 │ 48 │   │ 2024-12-09 11:20:47.789000000 │                  0 │ 1733743235620725316 │ 9999 │
2. │ 17 │ 833 │ 47 │   │ 2024-12-09 11:20:47.789000000 │                  0 │ 1733743235620740674 │ 9999 │
3. │ 73 │ 480 │ 14 │   │ 2024-12-09 11:20:47.789000000 │                  0 │ 1733743235620750341 │ 9999 │
4. │ 75 │ 918 │ 42 │   │ 2024-12-09 11:20:47.789000000 │                  0 │ 1733743235620755827 │ 9999 │
5. │ 96 │ 329 │  6 │   │ 2024-12-09 11:20:47.789000000 │                  0 │ 1733743235620765443 │ 9999 │
   └────┴─────┴────┴───┴───────────────────────────────┴────────────────────┴─────────────────────┴──────┘

5 rows in set. Elapsed: 0.053 sec. Processed 7.75 million rows, 29.58 MB (145.72 million rows/s., 556.33 MB/s.)
Peak memory usage: 3.06 MiB.
```

Deletes in Postgres are sent into the target with a peerdb_is_deleted column set to 1, replicating a logical delete.  You would therefore need to handle the fact that the record is only logically deleted either in your downstream ClickHouse views, reports or applications.  

```
SELECT *
FROM public_test
WHERE _peerdb_is_deleted = 1
LIMIT 5

Query id: 08008b42-20a7-47ae-b17a-84de2b5e33da

   ┌──────id─┬─c1─┬─c2─┬─t─┬─────────────_peerdb_synced_at─┬─_peerdb_is_deleted─┬─────_peerdb_version─┬─c3─┐
1. │ 1972374 │  0 │  0 │   │ 2024-12-09 11:12:26.595000000 │                  1 │ 1733742732447675833 │  0 │
2. │ 1972375 │  0 │  0 │   │ 2024-12-09 11:12:26.595000000 │                  1 │ 1733742732447679654 │  0 │
3. │ 1972385 │  0 │  0 │   │ 2024-12-09 11:12:26.595000000 │                  1 │ 1733742732447683362 │  0 │
4. │ 1972399 │  0 │  0 │   │ 2024-12-09 11:12:26.595000000 │                  1 │ 1733742732447686956 │  0 │
5. │ 1972403 │  0 │  0 │   │ 2024-12-09 11:12:26.595000000 │                  1 │ 1733742732447691313 │  0 │
   └─────────┴────┴────┴───┴───────────────────────────────┴────────────────────┴─────────────────────┴────┘

5 rows in set. Elapsed: 0.073 sec. Processed 7.05 million rows, 1.03 MB (97.14 million rows/s., 14.26 MB/s.)
Peak memory usage: 2.14 MiB.
```

### Schema Evolution

If you add a column onto your source table, this is automatically reflected in ClickHouse at the point that the next record is integrated.  

In the example below, we have added a new column c4 into Postgres, and found this to be created in ClickHouse with a default value:

```
SELECT *
FROM public_test
LIMIT 5

Query id: 2a370fd1-4652-4dc3-a3b7-4f50b8fa32cd

   ┌─id─┬──c1─┬───c2─┬─t─┬─c3─┬─────────────_peerdb_synced_at─┬─_peerdb_is_deleted─┬─_peerdb_version─┬─c4─┐
1. │  1 │ 581 │ 7417 │   │  0 │ 2024-12-09 14:51:15.151000000 │                  0 │               0 │  0 │
2. │  2 │ 242 │ 8599 │   │  0 │ 2024-12-09 14:51:15.151000000 │                  0 │               0 │  0 │
3. │  3 │ 793 │   67 │   │  0 │ 2024-12-09 14:51:15.151000000 │                  0 │               0 │  0 │
4. │  4 │ 444 │ 2072 │   │  0 │ 2024-12-09 14:51:15.151000000 │                  0 │               0 │  0 │
5. │  5 │ 956 │  609 │   │  0 │ 2024-12-09 14:51:15.151000000 │                  0 │               0 │  0 │
   └────┴─────┴──────┴───┴────┴───────────────────────────────┴────────────────────┴─────────────────┴────┘

5 rows in set. Elapsed: 0.004 sec.
```

Dropping a column in your source table does not remove it from ClickHouse, but should set the values to NULL in the target table.  

Please note that even though the new column is integrated, ClickHouse schema evolution is [not explicitly documented as being supported](https://docs.peerdb.io/features/schema-changes) so tread carefully when updating your source tables!

## Gotchas When Running An Open Source Stack

There are a few gotchas when runnning the open source stack which slowed us down with getting started.

The first is related to the MiniIO Configuration.  PeerDB takes data from Postgres and puts it in a staging area before it is loaded into ClickHouse.  By default this staging area is hosted in a [MinIO](https://min.io/) container which runs inside of the PeerDB Docker compose stack.  It is important to give ClickHouse a path to this container by setting a hostname in the docker compose file.  The value needs to change from this:

```
PEERDB_CLICKHOUSE_AWS_CREDENTIALS_AWS_ENDPOINT_URL_S3: http://host.docker.internal:9001
```

To the real IP address where MinIO is running:

```
PEERDB_CLICKHOUSE_AWS_CREDENTIALS_AWS_ENDPOINT_URL_S3: http://172.31.26.57:9001
```

Secondly, we experienced a number of issues relating to Docker Snap on Ubuntu.  This included containers in Docker compose not being able to connect to each other, and not being able to write to our external EBS volume.  Ensure that you have setup Docker following the instructions on their website for an easier time with PeerDB open source.

Aside from these gotchas, the Open Source PeerDB version was relatively easy to deploy and run and we found a single instance to be scalable to millions of rows with low latency.  

## Cloud Hosted Solution 

As mentioned, we have two options for a managed solution as of December 2024.  The first is [PeerDB Cloud](https://peerdb.io) and the second is to use [ClickHouse Cloud](https://clickhouse.com) which now integrates PeerDB to enable it's Postgres CDC solution.  

With PeerDB Cloud only supporting ClickHouse Cloud as a destination, it is logical that at some point it will be deprecated.  For that reason I would focus on the latter option if you want a fully managed solution.

You will need to [request access to the private preview via support](https://clickhouse.com/cloud/clickpipes/postgres-cdc-connector) to enable Postgres CDC in your Cloud account.

The process for configuring the peers and the mirror are similar to the PeerDB Open Source UI.  You create a ClickPipe associated with your ClickHouse Cloud instance and select the Postgres CDC option.  You can then specify the details for your source database, choose an area within your ClickHouse Cloud instance to write to and run through the process.

<Picture src={clickpipespostgres} alt="" />

It is also possible to monitor the running process in the Cloud UI.  You will see your process moving through the initial snapshot through to the stream processing.

<Picture src={clickpipespostgrescdc} alt="" />

The user interface is very similar to the open source version, but has been nicely integrated into the ClickHouse Cloud UI.  

## Conclusion 

Postgres and ClickHouse are highly complementary technologies for transactional and analytical workloads.  

Though there are various options for ETL and CDC between them, PeerDB is now the natural choice considering it's performance and their acquisition by ClickHouse Inc.  

The Open Source tool is very easy to setup, and the deep integration with ClickHouse cloud gives you the ability to run PeerDB for free (as of today) with no need for configuration, hosting or management, making it a compelling choice. 

</Article>